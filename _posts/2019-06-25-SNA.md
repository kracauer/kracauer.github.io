---
title: Social Network Analysis
subtitle: Homework // L13 Social Network Analysis (SNA)
---
<b>Task:</b> <i>Create a network of places in the “Dispatch” — if places are mentioned in the same article, they must be connected one way or the other — we can use that as the basis for creating edges. Generate a vizualisation in Gephi, only here you will need to create a geographical network, i.e., a network put over a real map: use Geo Layout plugin (your file with the data on nodes must also include coordinates). Describe your observations on your website as a separate blog post.</i>

### 1. Python Code for Preparation of Data Set

```python
from bs4 import BeautifulSoup
import re
import os

newPathToFolder = "Folder were given files are located"
pathToFolder = "Folder for loop results"
listOfFiles = os.listdir(pathToFolder)

# function with one argument filter to define a specific date which will use values of the dispatch only if the date is true
def generate(filter):

    placeNames = []
    dicFreq = {}
    resultsCSV = []

    # for loop to access all files
    for f in listOfFiles:
        soup = BeautifulSoup (open(pathToFolder+f, "r", encoding="utf8"), features="html.parser")
        
        # searches for list items of "date" and return maximum two elemens
        # only returns the second match
        issue_date = soup.find_all("date", limit=2)[1] 
        issue_date = issue_date.get("value")
        
        # searches for all tags with "div3" and stores it in variable "articles"
        articles = soup.find_all("div3", type = True)
        if issue_date.startswith(filter):
            
            # for loop that counts each article and combines it wit the date in the dispatch
            for a, item in enumerate(articles):
                counter = str(a) + "-" + str(issue_date)
                
                # continues to find all placenames with an attribute
                places = item.find_all("placename", key = True)
                
                # variable that holds the issue date of the dispatch a string and an article counter
                article = "article-" + counter                                  
               
                print(article)
                
                for a, item in enumerate(places):
                
                    # counter2 will be the unique identifier ID for each row
                    counter2 = str(a) + "-" + counter
                    
                    # for loop to retrieve all placenames as value from the placename tag
                    place = item.get_text()
                    
                    # variable that holds the tgn number
                    key = item["key"].split(";")                                
                    
                    print(str(place))
                    
                    # for loop to clean tgn numbers digits only
                    for k in key:
                        key = [d for d in k if d.isdigit()]                     
                        tag_id = ''.join(key)
                        
                        # creating a variable that holds each result article, place, tag_id
                        placeList = "\t".join([counter2,issue_date,article,place,tag_id])
                        
                        # appending the variable to a list
                        placeNames.append(placeList)                            

    # creating a frequency with a for loop for all placenames
    for i in placeNames:                                                        
        if i in dicFreq:
            dicFreq[i] += 1
        else:
            dicFreq[i]  = 1

    # removes all placenames that are mention once only if value < 2: 
    # this will exclude items with frequency higher than 1 - we want unique rows
    for key, value in dicFreq.items():                                          
            newVal = "%09d\t%s" % (value, key)
            # newVal will looks like: `000005486 TAB Richmond`
            resultsCSV.append(newVal)

    # sorting the results variable
    resultsCSV = sorted(resultsCSV, reverse=True)                               
    
    print(len(resultsCSV)) # will print out the number of items in the list
    
    # joining the results line by line
    resultsToSave = "\n".join(resultsCSV)                                       

    # creates a new file in a target folder with name + article counter + name + issue_date + txt file
    newfile = newPathToFolder  + "matched_list.csv"
    
    # creating a header for the final file
    header = "freq\tid\tdate\tsource\ttarget\ttgn\n"
    
    # opens the newfile and writes each article into a sperate file
    with open(newfile, "w", encoding="utf8") as f8:
        f8.write(header+"".join(resultsToSave))

# starts function
generate("1860-11")
```

### 2. The Results of Preparation

Due to the long calculation time only the articles of the "Daily Dispatch" of the month November 1860 ("1860-11") were processed. For the calculation of this one month my computer already took 726 seconds, about 12 minutes.

<img src="/img/726_seconds.png"/>

After processing, the data set is available in the following form:

<img src="/img/1861-02-list.png"/>

### 3. Visualization with Gephi

The same applies to Gephi as to most visualization programs: Without the right preparation of the data and without the right settings, you don't get scientific hints, only artistic artefacts. For example: A first attempt to display the data generated above.

<img src="/img/purely_artisticel.png"/>

In order to keep the ratio of input-out during the visualization as comprehensible as possible, we initially only use four parameters in the "Overview" field. 

<img src="/img/arbeitsbereiche_gephi.png"/>

Once we are familiar with the data set and its behavior within Gephi, more parameters can be applied. The parameters to start with are: Average Degree, Average Weighted Degree, Modularity and Eigenvector Centrality.

<img src="/img/settings_gephi_statistics.png"/>

For the layout type we select "Force Atlas 2" and the settings recommended by Maxim Romanov:

<img src="/img/recommended_setting_atlas_2.png"/>

The classes created by the "Modularity" command can be applied as colors to the data ball by selecting the following settings: Appearance --> Nodes --> Partition --> Modularity Class
Used correctly, they can significantly improve the clarity of the data.

In the last step we switch to the field "Preview". Here we apply the setting "Default Curved" under "Preview Settings". Due to the condensed form, we can see "Modularity Classes" even better.

<img src="/img/123.png"/>
