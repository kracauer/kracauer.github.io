---
title: Processing Geographical Data
subtitle: Homework // L10 Text to Map (1/2)
---
<b>Task:</b> <i>GISting the “Dispatch” II: Mapping geographical data from the “Dispatch”</i><br>

<b>Task 1:</b> <i>Extract toponyms (place names) from the “Dispatch” (python)</i><br>
<b>Task 2:</b> <i>Calculate their frequencies (python)</i><br>
<b>Task 3:</b> <i>Generate files for all years, all months, and all days (you can save results in subfolders, but, better, in single files with dates in another column)</i><br>

### Solution 1 and 2: Extracting toponyms and counting frequencies

```python
from bs4 import BeautifulSoup
import re
import os

newPathToFolder = ""
pathToFolder = ""
listOfFiles = os.listdir(pathToFolder)

# function with one argument filter to define a specific date which will use values of the dispatch only if the date is true
def generate(filter):

    placeNames = []
    dicFreq = {}
    resultsCSV = []

    # for loop to access all files
    for f in listOfFiles:
        soup = BeautifulSoup (open(pathToFolder+f, "r", encoding="utf8"), features="html.parser")
        
        # searches for list items of "date" and return maximum two elemens
        issue_date = soup.find_all("date", limit=2)[1] # only returns the second match
        issue_date = issue_date.get("value")
       
        # searches for all tags with "div3" and stores it in variable "articles"
        articles = soup.find_all("div3", type = True)
        if issue_date.startswith(filter):
            
            # for loop that counts each article and combines it wit the date in the dispatch
            for a, item in enumerate(articles):
               
                counter = str(a) + "-" + str(issue_date)                        
                
                # continues to find all placenames with an attribute
                places = item.find_all("placename", key = True)                
                
                # variable that holds the issue date of the dispatch a string and an article counter
                article = "article-" + counter                                  
                print(article)
                
                # for loop to retrieve all placenames as value from the placename tag
                for a, item in enumerate(places):
                
                    # counter2 will be the unique identifier ID for each row
                    place = item.get_text()                                     
                    counter2 = str(a) + "-" + counter                           
                    
                    # variable that holds the tgn number
                    key = item["key"].split(";")                               
                    print(str(place))

                    # for loop to clean tgn numbers digits only
                    # creating a variable that holds each result article, place, tag_id
                    for k in key:
                        key = [d for d in k if d.isdigit()]                     
                        tag_id = ''.join(key)
                        placeList = "\t".join([counter2,issue_date,article,place,tag_id])        
                        
                        # appending the variable to a list for i in placeNames:
                        placeNames.append(placeList)
                        
        # creating a frequency with a for loop for all placenames
        if i in dicFreq:
            dicFreq[i] += 1
        else:
            dicFreq[i]  = 1
    # removes all placenames that are mention once only if value < 2: # this will exclude items with frequency higher than 1 - we want      unique rows
    for key, value in dicFreq.items():                                          
            newVal = "%09d\t%s" % (value, key)
            
            # newVal will looks like: `000005486 TAB Richmond`
            resultsCSV.append(newVal)

    # sorting the results variable
    resultsCSV = sorted(resultsCSV, reverse=True)                               
    
    # will print out the number of items in the list
    print(len(resultsCSV)) 
    
    # joining the results line by line
    resultsToSave = "\n".join(resultsCSV)                                       

    # creates a new file in a target folder with name + article counter + name + issue_date + txt file
    newfile = newPathToFolder  + "placesFull_3.3.csv"
    
    # creating a header for the final file
    header = "freq\tid\tdate\tsource\ttarget\ttgn\n"
    
    # opens the newfile and writes each article into a sperate file
    with open(newfile, "w", encoding="utf8") as f8:
        f8.write(header+"".join(resultsToSave))

# how to use the function
generate("1861-02")
```


### Solution 3: Generating the Files
Due to hardware constraints, the script could only be run for one month and not every 60 months of all five years of the "Daily Dispatch". For this purpose, the month of February 1861 was randomly chosen. The extraction and measurement took 514 seconds, about 8.5 minutes.

<img src="/img/1861-02_runtime.png"/>

The list created for February 1861 begins as follows: 
