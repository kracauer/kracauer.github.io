---
title: Processing Geographical Data
subtitle: Homework // L10 Text to Map (1/2)
---
<b>Task:</b> <i>GISting the “Dispatch” II: Mapping geographical data from the “Dispatch”</i><br>

<b>Task 1:</b> <i>Extract toponyms (place names) from the “Dispatch” (python)</i><br>
<b>Task 2:</b> <i>Calculate their frequencies (python)</i><br>
<b>Task 3:</b> <i>Generate files for all years, all months, and all days (you can save results in subfolders, but, better, in single files with dates in another column)</i><br>

### Solution 1 and 2: Extracting toponyms and counting frequencies

```python
from bs4 import BeautifulSoup
import re
import os

source = "Directory of given files"
destination = " Directory for output"
listOfFiles = os.listdir(source)

# function extracts and list place names and related variables and compiles them into a single destination file
def generate(filter):

    # initialization
    placeNames = []
    dicFreq = {}
    resultsCSV = []

    # loops over directory
    for f in listOfFiles:
    
        # opens file
        file_handle = open(source+f, "r", encoding="utf8")
        
        # parse input using soup's html.parser
        soup = BeautifulSoup (file_handle, features="html.parser")
        
        # extracts the value of the relevant date tag
        issue_date_obj = soup.find_all("date", limit=2)[1]
        issue_date = issue_date_obj.get("value")
        
        # finds all div3 containers
        articles = soup.find_all("div3", type = True)
        
        # applies given prefix filter (expected format: YYYY or YYYY-MM or YYYY-MM-DD)
        if issue_date.startswith(filter):
            
            # loops over all articles
            for a, item in enumerate(articles):
                
                # prepares unique id for each article
                counter = str(a) + "-" + str(issue_date)                        
                article = "article-" + counter
                
                # debug print
                print(article)
                
                # finds all non null place names in the article
                places = item.find_all("placename", key = True)
                
                # loops over all place names in one given article
                for a, item in enumerate(places):
                
                    # prepares unique id for each generated set of data
                    counter2 = str(a) + "-" + counter                           
                    
                    # extracts the actual place name
                    place = item.get_text()
                    
                    # extracts the tgn number
                    key = item["key"].split(";")
                    
                    # debug print
                    print(str(place))

                    # extracts only digits from tgn tag
                    for k in key:
                        key = [d for d in k if d.isdigit()]   
                        
                        # composes one set of data
                        tag_id = ''.join(key)
                        placeList = "\t".join([counter2,issue_date,article,place,tag_id])        
                        
                        # appends set of data to list
                        placeNames.append(placeList)
                        
    # sets frequency to 1 (for better use with QGIS)
    dicFreq[i]  = 1

    # sorts results by unique id
    resultsCSV = sorted(resultsCSV, reverse=True)                               
    
    # prints amount of data sets
    print(len(resultsCSV)) 
    
    # creates table from data sets
    resultsToSave = "\n".join(resultsCSV)                                       

    # sets destination file name
    newfile = destination  + "placesFull_3.3.csv"
    
    # creates header in destination file
    header = "freq\tid\tdate\tsource\ttarget\ttgn\n"
    
    # creates and opens destination file to write content
    with open(newfile, "w", encoding="utf8") as f8:
        f8.write(header+"".join(resultsToSave))

# executes function
generate("1861-02")
```


### Solution 3: Generating the Files
Due to hardware constraints, the script could only be run for one month and not every 60 months of all five years of the "Daily Dispatch". For this purpose, the month of February 1861 was randomly chosen. The extraction and measurement took 514 seconds, about 8.5 minutes.

<img src="/img/1861-02_runtime.png"/>

The list created for February 1861 begins as follows: 
